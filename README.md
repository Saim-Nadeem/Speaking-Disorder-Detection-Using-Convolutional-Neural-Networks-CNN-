ğŸ§  Dysarthria Detection Using Convolutional Neural Networks (CNN)

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/Framework-TensorFlow-orange.svg)](https://www.tensorflow.org/)
[![Librosa](https://img.shields.io/badge/Audio%20Processing-Librosa-yellow.svg)](https://librosa.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> A deep learning-based system for detecting dysarthria (motor speech disorder) from audio recordings using MFCC features and 1D CNNs.

---

## ğŸ“Œ Overview
This project uses **Convolutional Neural Networks** (CNNs) to identify **dysarthria**, a speech impairment, from `.wav` audio samples.  
It extracts audio features using **Librosa** and classifies speech as **normal** or **dysarthric** using a supervised learning model.

---

## ğŸ“‚ Folder Structure

```
â”œâ”€â”€ All Dys Wav/             # ğŸ§‘â€âš•ï¸ Dysarthric speech samples (training)
â”œâ”€â”€ All Non Dys Wav/         # ğŸ™‚ Normal speech samples (training)
â”œâ”€â”€ Testing Dataset/         # ğŸ§ª Testing speech samples
â”œâ”€â”€ images/
â”‚   â””â”€â”€ img1.png             # ğŸ–¼ï¸ Model diagram or visual
â”œâ”€â”€ Dysarthria_Detection.ipynb   # ğŸ§  Jupyter notebook for full training and prediction
â”œâ”€â”€ README.md                # ğŸ“˜ This documentation file
```

---

## ğŸ” Feature Extraction

Features are extracted from `.wav` files using the `librosa` library:
- ğŸ™ï¸ MFCC (Mel Frequency Cepstral Coefficients)
- ğŸµ Chroma
- ğŸ“Š Spectral Contrast
- âœ‚ï¸ Zero-Crossing Rate
- ğŸ§  Tonnetz

---

## ğŸ§  CNN Model Architecture

| Layer           | Description                             |
|----------------|-----------------------------------------|
| Conv1D         | Extracts temporal patterns from MFCCs   |
| MaxPooling1D   | Downsamples feature maps                |
| Flatten        | Converts output into a dense vector     |
| Dense          | Fully connected layer                   |
| Dropout        | Prevents overfitting                    |
| Softmax        | Outputs probabilities for 2 classes     |

---

## ğŸ§ª Sample Prediction Output

```
Input File: patient_042.wav
Prediction: Dysarthric Speech (Class 1)
Confidence: 91.7%
```

---

## â–¶ï¸ How to Run

1ï¸âƒ£ **Clone the Repository**
```bash
git clone https://github.com/Saim-Nadeem/Dysarthria-Detection-CNN.git
cd Dysarthria-Detection-CNN
```

2ï¸âƒ£ **Install Dependencies**
```bash
pip install -r requirements.txt
```

3ï¸âƒ£ **Launch Notebook**
```bash
jupyter notebook Dysarthria_Detection.ipynb
```

4ï¸âƒ£ **Upload and Predict**
- Use the testing cell to classify new `.wav` files from the `Testing Dataset/` folder.

---

## ğŸ›  Technologies Used

- ğŸ Python 3.9+
- ğŸ§  TensorFlow / Keras
- ğŸ§ Librosa
- ğŸ“Š NumPy, Pandas
- ğŸ“‰ Scikit-learn (for train/test split, evaluation)

---

## ğŸ”® Future Work

- ğŸŒ€ Add LSTM/RNN for sequential modeling
- ğŸ–¼ Convert MFCC to spectrograms for 2D CNN
- ğŸŒ Deploy as web service using Flask or Streamlit

---

## ğŸ–¼ Image

![Model Overview](images/img1.png)

---

## ğŸ“œ License

This project is licensed under the **MIT License**.  
See the [LICENSE](LICENSE) file for more details.

---

## ğŸ‘¤ Author

**Saim Nadeem**  
ğŸ”— GitHub: [Saim-Nadeem](https://github.com/Saim-Nadeem)
