ğŸ§  Speaking Disorder Detection Using Convolutional Neural Networks (CNN)

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/Framework-TensorFlow-orange.svg)](https://www.tensorflow.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> A deep learning solution to identify speaking disorders, specifically **dysarthria**, using **audio feature extraction** and **1D CNNs**.

---

## ğŸ“Œ Project Overview

This project detects **dysarthric speech** using **Mel-Frequency Cepstral Coefficients (MFCC)** and other spectral audio features. The model classifies `.wav` files as either **normal** or **disordered** speech with high accuracy.

---

## ğŸ“‚ Folder Structure

```
â”œâ”€â”€ All Dys Wav/             # ğŸ§‘â€âš•ï¸ Dysarthric audio samples (label: 1)
â”œâ”€â”€ All Non Dys Wav/         # ğŸ™‚ Normal speech samples (label: 0)
â”œâ”€â”€ Testing Dataset/         # ğŸ§ª Additional unseen test samples
â”œâ”€â”€ images/                  # ğŸ–¼ï¸ Contains model diagram and screenshots
â”‚   â””â”€â”€ img1.png
â”œâ”€â”€ Dysarthria_Detection.ipynb   # ğŸ§  Main training and evaluation notebook
â”œâ”€â”€ README.md                # ğŸ“˜ You are here
```

---

## ğŸ” Feature Extraction

Speech files are processed using `librosa` to extract:
- MFCC (Mel-Frequency Cepstral Coefficients)
- Chroma Features
- Spectral Contrast
- Tonnetz
- Zero-Crossing Rate

---

## ğŸ§  CNN Model Architecture

| Layer Type     | Description                                  |
|----------------|----------------------------------------------|
| Conv1D         | Extracts patterns from MFCCs                 |
| MaxPooling1D   | Downsamples feature maps                     |
| Flatten        | Flattens output for dense layers             |
| Dense + Dropout| Fully connected layers to prevent overfitting|
| Softmax        | Final classification output layer            |

---

## ğŸ§ª Sample Output

```
Input: dys_001.wav
Predicted Class: 1 (Dysarthric Speech)
Confidence: 93.4%
```

---

## â–¶ï¸ How to Run

1ï¸âƒ£ **Clone the repository**
```bash
git clone https://github.com/Saim-Nadeem/Speaking-Disorder-Detection-Using-Convolutional-Neural-Networks-CNN-.git
cd Speaking-Disorder-Detection-Using-Convolutional-Neural-Networks-CNN-
```

2ï¸âƒ£ **Install dependencies**
```bash
pip install -r requirements.txt
```

3ï¸âƒ£ **Launch Jupyter Notebook**
```bash
jupyter notebook Dysarthria_Detection.ipynb
```

4ï¸âƒ£ **Run all cells**
- Upload your test `.wav` files in the **Testing Dataset/** folder
- Watch the model predict normal or disordered speech

---

## ğŸ›  Requirements

- Python 3.9+
- TensorFlow
- Keras
- librosa
- scikit-learn
- numpy, pandas, matplotlib

---

## ğŸ–¼ Visual Overview

![Model Visualization](images/img1.png)

---


## ğŸ‘¤ Author

**Saim Nadeem**  
ğŸ”— GitHub: [Saim-Nadeem](https://github.com/Saim-Nadeem)
